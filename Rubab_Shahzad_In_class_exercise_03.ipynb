{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rubab Shahzad In-class-exercise-03.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8igGnQObir00gnAz6TO8g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubabshz/Rubab_INFO5731_Spring2020/blob/main/Rubab_Shahzad_In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQN4RmeDJZOV"
      },
      "source": [
        "The third In-class-exercise (2/2/2021, 20 points in total)\r\n",
        "The purpose of this exercise is to understand users' information needs, then collect the data for analysis.\r\n",
        "\r\n",
        "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-8r76EdJcOT"
      },
      "source": [
        " # Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\r\n",
        "\r\n",
        "'''\r\n",
        "For the purpose of this in-class exercise, I evaluated the country specific top twitter trends of select countries, where the data is printed out. \r\n",
        "Another dataset for searching for twitter hashtags is given, in which case the data is stored in a file.\r\n",
        "I chose two sepaprate formats, to understand the user's approach on this kind of data, as well as provide the user with free (sample), and/or input possible data.\r\n",
        "\r\n",
        "This shows the user, the comparison of the top trends of tweets amnong several randomly selected countries around the world. And also allows the user to search for a specific hashtag.\r\n",
        "This can be either from the list of top tweet trends printed or anything else the user desires.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiprZRWlJh3J"
      },
      "source": [
        "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihzZCXWLa4xv",
        "outputId": "a6f30e47-46ec-4b36-95a1-52a65f5410e9"
      },
      "source": [
        "!pip install tweepy\r\n",
        "!pip install pandas\r\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_3_w3RCGFLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6722b5ba-7e18-4cb1-be3c-407d8afa7230"
      },
      "source": [
        "\r\n",
        "\r\n",
        "import json\r\n",
        "import tweepy\r\n",
        "import csv\r\n",
        "import sys\r\n",
        "\r\n",
        "\r\n",
        "with open('twitter_credentials.json', 'w') as secret_info:\r\n",
        "  json.dump(twitter_cred, secret_info, indent=4, sort_keys=True)\r\n",
        "\r\n",
        "\r\n",
        "# Twitter API credentials\r\n",
        "\r\n",
        "with open('twitter_credentials.json') as cred_data:\r\n",
        "  info = json.load(cred_data)\r\n",
        "  consumer_key = info['CONSUMER_KEY']\r\n",
        "  consumer_secret = info['CONSUMER_SECRET']\r\n",
        "  access_key = info['ACCESS_KEY']\r\n",
        "  access_secret = info['ACCESS_SECRET']\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\r\n",
        "  api = tweepy.API(auth)\r\n",
        "\r\n",
        "  # Mention the maximum number of tweets that the user wants to extract\r\n",
        "\r\n",
        "  maximum_number_of_tweets_to_be_extracted = int(input('Enter the number of tweets that you want to extract- '))\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "  hashtag = input('Enter the hashtag you want to scrape- ')\r\n",
        "\r\n",
        "  for tweet in tweepy.Cursor(api.search, q='#' + hashtag, rpp=100).items(maximum_number_of_tweets_to_be_extracted):\r\n",
        "    with open('tweets_with_hashtag_' + hashtag + '.txt', 'a') as the_file:\r\n",
        "       the_file.write(str(tweet.text.encode('utf-8')) + '\\n')\r\n",
        "  print ('Extracted ' + str(maximum_number_of_tweets_to_be_extracted) + ' tweets with hashtag #' + hashtag)\r\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the number of tweets that you want to extract- 500\n",
            "Enter the hashtag you want to scrape- Biden\n",
            "Extracted 500 tweets with hashtag #Biden\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQWGIvl3s5ep",
        "outputId": "4b84f670-3fdc-46d8-e481-d59aaec4cde6"
      },
      "source": [
        "\r\n",
        "#Earth ID for United States, Kuwait, Turkey, Spain, South Africa, France, and Germany are examined for top and trending tweets\r\n",
        "\r\n",
        "United_States_WOE_ID = 2352824\r\n",
        "Kuwait_WOE_ID = 23424870\r\n",
        "Turkey_WOE_ID = 23424969\r\n",
        "South_Africa_WOE_ID = 23424942\r\n",
        "Spain_WOE_ID = 23424950\r\n",
        "France_WOE_ID = 23424819\r\n",
        "Germany_WOE_ID = 23424829\r\n",
        "\r\n",
        "\r\n",
        "#Using API to call for country specific trends\r\n",
        "\r\n",
        "us_trends = api.trends_place(United_States_WOE_ID)\r\n",
        "kwt_trends = api.trends_place(Kuwait_WOE_ID)\r\n",
        "turk_trends = api.trends_place(Turkey_WOE_ID)\r\n",
        "spain_trends = api.trends_place(Spain_WOE_ID)\r\n",
        "saf_trends = api.trends_place(South_Africa_WOE_ID)\r\n",
        "fr_trends = api.trends_place(France_WOE_ID)\r\n",
        "gr_trends = api.trends_place(Germany_WOE_ID)\r\n",
        "\r\n",
        "\r\n",
        "#Printing for each given country\r\n",
        "\r\n",
        "\r\n",
        "trends = json.loads(json.dumps(us_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        "  \r\n",
        "trends = json.loads(json.dumps(kwt_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        "\r\n",
        "trends = json.loads(json.dumps(turk_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        " \r\n",
        "trends = json.loads(json.dumps(spain_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        " \r\n",
        "\r\n",
        "trends = json.loads(json.dumps(saf_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        " \r\n",
        "\r\n",
        "trends = json.loads(json.dumps(fr_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        " \r\n",
        "\r\n",
        "trends = json.loads(json.dumps(gr_trends, indent=1))\r\n",
        " \r\n",
        "for trend in trends[0][\"trends\"]:\r\n",
        "\tprint (trend[\"name\"])\r\n",
        "\r\n",
        "print(\"______________________________The END____________________________________\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Marie\n",
            "#KnuckleMania\n",
            "#FramingBritneySpears\n",
            "#WeHadSexAndNow\n",
            "#DragRace\n",
            "Lou Dobbs\n",
            "Jose Canseco\n",
            "Zendaya\n",
            "FFXIV\n",
            "Billy Football\n",
            "Kodak\n",
            "Jayson Tatum\n",
            "Sage\n",
            "Lamelo\n",
            "Carsen Edwards\n",
            "WE LOVE YOU DREAM\n",
            "Chris Leben\n",
            "Big Bird\n",
            "Teague\n",
            "Raptors\n",
            "Durant\n",
            "Adam Silver\n",
            "Symone\n",
            "Hart\n",
            "Tamisha\n",
            "Paige VanZant\n",
            "Donato\n",
            "Grimace\n",
            "Kandy\n",
            "Dat Nguyen\n",
            "John David Washington\n",
            "Ridiculousness\n",
            "Lou Will\n",
            "Lunar Whale\n",
            "The NBA\n",
            "Britt Reid\n",
            "Kyle Lowry\n",
            "FINAL FANTASY XIV\n",
            "Marvel\n",
            "Estinien\n",
            "Grant Williams\n",
            "Luke Kennard\n",
            "SBI RUST SERVER\n",
            "X-Men\n",
            "Martin Jones\n",
            "Zenos\n",
            "Pritchard\n",
            "Jamie Spears\n",
            "#RnR13\n",
            "#كورونا_الكويت\n",
            "#مقاطعه_المنتجات_الفرنسيه102\n",
            "#لن_نغلق\n",
            "#الدرس_الذي_تعلمته_في_حياتك\n",
            "#kilaw\n",
            "زاد الضيق\n",
            "علي البال\n",
            "الكلام الحلو\n",
            "علي الدنيا\n",
            "اسبانيا\n",
            "نور علي نور\n",
            "القادسيه\n",
            "مرزوق\n",
            "اللهم الجنه\n",
            "ابو باسل\n",
            "Tells\n",
            "عزيزي الفلنتاين\n",
            "علي الفاضي\n",
            "لبنان\n",
            "تيك توك\n",
            "المسلمات الاحياء\n",
            "يعقوب\n",
            "ليكن الليل\n",
            "جبر خاطر\n",
            "محمد عبده\n",
            "Snapchat\n",
            "#صباح_الخير\n",
            "#tellonym\n",
            "#اسقاط_القروض_لليوم_790\n",
            "#ErdoganinYanindayiz\n",
            "Tviitırrgt Açıldı\n",
            "#NurcanSerceTutuklansın\n",
            "#FakülteyiSarayaKur\n",
            "#BugünGünlerdenGALATASARAY\n",
            "#ŞampiyonlukAteşi\n",
            "Boğaziçi Hukuk\n",
            "Recep Tayyip Erdoğan\n",
            "BU DÜNYAYI YAKARIZ SENİN İÇİN\n",
            "Resmi Gazete'de\n",
            "İletişim Fakültesi\n",
            "Dünya 5\n",
            "Güçlü Türkiye\n",
            "Rabbime\n",
            "S-400\n",
            "HakanınŞifası AnneŞefkati\n",
            "Ölümüne\n",
            "#CovidAldatmacası\n",
            "#UYKUSUZ36SAAT\n",
            "#Haftasonu\n",
            "#OurNewBeginningWithMarkTuan\n",
            "#Benidefişle\n",
            "#CumhurbaskanımınYanındayım\n",
            "#BizFenerbahceyiz\n",
            "#YanındayızErdoğan\n",
            "#YüreğimizYetiyor\n",
            "#mezbiyen\n",
            "#DayanKalbim\n",
            "#KadıköyünFatihiTerim\n",
            "#KONSANTRASYON\n",
            "#YetersizBakiyeAkp\n",
            "#StadDeğilTARLA\n",
            "#İzmirEmniyetteNelerOluyor\n",
            "#Reis\n",
            "#bizdeordaydık\n",
            "#MilenioLive\n",
            "#FelizCumpleSam\n",
            "FFXIV\n",
            "#FreeBritney\n",
            "Sage\n",
            "Fognini\n",
            "Endwalker\n",
            "#aot137spoilers\n",
            "#prelemi\n",
            "Giulia\n",
            "FINAL FANTASY XIV\n",
            "Dayane\n",
            "Berrettini\n",
            "Pier\n",
            "Quique San Francisco\n",
            "Christopher Plummer\n",
            "Sergio\n",
            "Malcolm & Marie\n",
            "Zenga\n",
            "Durant\n",
            "Rosalinda\n",
            "'Time'\n",
            "pueblo de españa\n",
            "Rusia\n",
            "Ley de Financiación\n",
            "Roma Gallardo\n",
            "Bautista\n",
            "Partidos Políticos\n",
            "Clippers\n",
            "Celtics\n",
            "Tatum\n",
            "Berlín\n",
            "Kemba\n",
            "Iker Jiménez\n",
            "Gracias Karchez\n",
            "YouTubers\n",
            "Kawhi\n",
            "Joan Planas\n",
            "Jujutsu Kaisen\n",
            "Levi\n",
            "Zverev\n",
            "Doria\n",
            "Borrell\n",
            "Zion\n",
            "Pablo Carreño\n",
            "Mark\n",
            "Fatui\n",
            "Chile\n",
            "Samantha\n",
            "Biden\n",
            "#ZumaAppreciationDay\n",
            "#stopforcingthings\n",
            "#WhatIWantFromBlackTwitter\n",
            "Tito\n",
            "Kigali\n",
            "#DJSBU\n",
            "#ICYPARK\n",
            "Clippers\n",
            "Happy Sabbath\n",
            "Zendaya\n",
            "Marie\n",
            "Lilo\n",
            "Condolences\n",
            "Bromhof\n",
            "Vuyani\n",
            "Malema\n",
            "Fortuner\n",
            "Venom\n",
            "Thanks God\n",
            "De Kock\n",
            "Nigeria\n",
            "national party\n",
            "Northriding\n",
            "Cyril\n",
            "Bob Marley\n",
            "Ngcobo\n",
            "Minister\n",
            "New Dawn\n",
            "Kaizer\n",
            "Zakes\n",
            "Bavuma\n",
            "Oreo\n",
            "Nkandla\n",
            "Mask\n",
            "The Lord\n",
            "i30 N\n",
            "Beyoncé\n",
            "Kevin\n",
            "Harden\n",
            "Root\n",
            "Democrats\n",
            "Eskom\n",
            "SABC\n",
            "ANC and EFF\n",
            "Bloubosrand\n",
            "Helen\n",
            "Growing\n",
            "Lindiwe\n",
            "Democracy\n",
            "Elon\n",
            "#FFXIV\n",
            "#stopcouvrefeu\n",
            "#Endwalker\n",
            "Kevin Durant\n",
            "#OurNewBeginningWithMarkTuan\n",
            "Kemba\n",
            "Lowry\n",
            "Kawhi\n",
            "#SmackDown\n",
            "Tatum\n",
            "Malcolm\n",
            "Sage\n",
            "lavine\n",
            "Zendaya\n",
            "Nets\n",
            "NEVER BEEN SO DEFENCELESS\n",
            "IKEA\n",
            "Harden\n",
            "Sabonis\n",
            "Vucevic\n",
            "Irving\n",
            "Boston\n",
            "bonne nuit\n",
            "Rec 118\n",
            "Pacers\n",
            "Bulls\n",
            "Diallo\n",
            "Maki\n",
            "Brooklyn\n",
            "Thunder\n",
            "Booker\n",
            "Paul George\n",
            "Christopher Plummer\n",
            "Giannis\n",
            "Evan Peters\n",
            "Dort\n",
            "dors\n",
            "4h30\n",
            "Kyrie\n",
            "Clippers\n",
            "Gaston\n",
            "beal\n",
            "Kodak\n",
            "Lamelo\n",
            "Habbo\n",
            "Trappes\n",
            "Uganda\n",
            "Stade de France\n",
            "Jujutsu Kaisen\n",
            "Fognini\n",
            "#FFXIV\n",
            "#Endwalker\n",
            "#FinalFantasyXIV\n",
            "Sage\n",
            "NEVER BEEN SO DEFENCELESS\n",
            "#frontexfiles\n",
            "#aot137spoilers\n",
            "Yoshi\n",
            "Moin Rübe\n",
            "Somalia\n",
            "Healer\n",
            "Levi\n",
            "Rossmann\n",
            "Venti\n",
            "Biden\n",
            "Calli\n",
            "Louis Tomlinson\n",
            "Christopher Plummer\n",
            "Britney Spears\n",
            "Ausrottung\n",
            "Marie\n",
            "Jesus\n",
            "guten morgen ihr lieben\n",
            "zeke\n",
            "Simfy\n",
            "attest\n",
            "Kiara\n",
            "Hyungwon\n",
            "chloe\n",
            "Trailer\n",
            "WandaVision\n",
            "spieltag\n",
            "Uhrzeit\n",
            "Fatou\n",
            "Guten Morgen Welt\n",
            "Schlafrhythmus\n",
            "siyeon\n",
            "Muttersprache\n",
            "Nigeria\n",
            "Trump\n",
            "WACH\n",
            "Nächte\n",
            "President\n",
            "Cola\n",
            "Prost\n",
            "digga\n",
            "Promo\n",
            "Zendaya\n",
            "floch\n",
            "Nighty\n",
            "______________________________The END____________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}